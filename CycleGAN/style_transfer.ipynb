{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import save_image\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from models import Generator\n",
    "from datasets import ImageDataset\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--batchSize', type=int, default=1, help='size of the batches')\n",
    "parser.add_argument('--dataroot', type=str, default='datasets/duke2market/', help='root directory of the dataset')\n",
    "parser.add_argument('--input_nc', type=int, default=3, help='number of channels of input data')\n",
    "parser.add_argument('--output_nc', type=int, default=3, help='number of channels of output data')\n",
    "parser.add_argument('--size', type=int, default=256, help='size of the data (squared assumed)')\n",
    "parser.add_argument('--cuda', action='store_true', help='use GPU computation')\n",
    "parser.add_argument('--n_cpu', type=int, default=8, help='number of cpu threads to use during batch generation')\n",
    "parser.add_argument('--generator_A2B', type=str, default='output/7/netG_A2B.pth', help='A2B generator checkpoint file')\n",
    "parser.add_argument('--generator_B2A', type=str, default='output/7/netG_B2A.pth', help='B2A generator checkpoint file')\n",
    "opt = parser.parse_args(['--cuda'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert tensor to image for displaying\n",
    "def tensor_to_image(tensor):\n",
    "    tensor = tensor.clone().detach().cpu()  # Clone the tensor to avoid modifying the original and move to CPU\n",
    "    tensor = tensor.squeeze(0)  # Remove batch dimension\n",
    "    tensor = tensor * torch.tensor([0.5, 0.5, 0.5]).view(3, 1, 1) + torch.tensor([0.5, 0.5, 0.5]).view(3, 1, 1)  # De-normalize\n",
    "    tensor = tensor.permute(1, 2, 0)  # Change from CxHxW to HxWxC\n",
    "    tensor = tensor.numpy()  # Convert to numpy array\n",
    "    tensor = (tensor * 255).astype(np.uint8)  # Convert to uint8\n",
    "    return tensor\n",
    "\n",
    "# Function to deprocess and display image\n",
    "def deprocess_image(image):\n",
    "    image = image.squeeze(0)  # Remove batch dimension\n",
    "    image = image * 0.5 + 0.5  # De-normalize to [0, 1]\n",
    "    image = image.clamp(0, 1)\n",
    "    return transforms.ToPILImage()(image)\n",
    "\n",
    "if torch.cuda.is_available() and not opt.cuda:\n",
    "    print(\"WARNING: You have a CUDA device, so you should probably run with --cuda\")\n",
    "\n",
    "###### Definition of variables ######\n",
    "# Networks\n",
    "G_duke_market = Generator(opt.input_nc, opt.output_nc)\n",
    "G_market_duke = Generator(opt.output_nc, opt.input_nc)\n",
    "\n",
    "if opt.cuda:\n",
    "    G_duke_market.cuda()\n",
    "    G_market_duke.cuda()\n",
    "\n",
    "# Load state dicts\n",
    "G_duke_market.load_state_dict(torch.load(opt.generator_A2B))\n",
    "G_market_duke.load_state_dict(torch.load(opt.generator_B2A))\n",
    "\n",
    "# Set model's test mode\n",
    "G_duke_market.eval()\n",
    "G_market_duke.eval()\n",
    "\n",
    "# Inputs & targets memory allocation\n",
    "Tensor = torch.cuda.FloatTensor if opt.cuda else torch.Tensor\n",
    "input_A = Tensor(opt.batchSize, opt.input_nc, opt.size, opt.size)\n",
    "input_B = Tensor(opt.batchSize, opt.output_nc, opt.size, opt.size)\n",
    "\n",
    "crop_size_w = 128\n",
    "crop_size_h = 256\n",
    "# Dataset loader\n",
    "transform = transforms.Compose([\n",
    "    #transforms.Resize((crop_size_h, crop_size_w)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'transform' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 24\u001b[0m\n\u001b[1;32m     21\u001b[0m image_paths \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(market_train_dic\u001b[38;5;241m.\u001b[39mvalues())[\u001b[38;5;241m200\u001b[39m:\u001b[38;5;241m201\u001b[39m] \n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m#image_paths = random_image_paths\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m images \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_path\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mRGB\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mimage_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mimage_paths\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Ensure image is in RGB mode\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# Apply the transformations\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m#transformed_image = transforms(image)\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m image \u001b[38;5;129;01min\u001b[39;00m images: \n",
      "Cell \u001b[0;32mIn[1], line 24\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     21\u001b[0m image_paths \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(market_train_dic\u001b[38;5;241m.\u001b[39mvalues())[\u001b[38;5;241m200\u001b[39m:\u001b[38;5;241m201\u001b[39m] \n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m#image_paths = random_image_paths\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m images \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[43mtransform\u001b[49m(Image\u001b[38;5;241m.\u001b[39mopen(image_path)\u001b[38;5;241m.\u001b[39mconvert(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRGB\u001b[39m\u001b[38;5;124m'\u001b[39m)) \u001b[38;5;28;01mfor\u001b[39;00m image_path \u001b[38;5;129;01min\u001b[39;00m image_paths)  \u001b[38;5;66;03m# Ensure image is in RGB mode\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# Apply the transformations\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m#transformed_image = transforms(image)\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m image \u001b[38;5;129;01min\u001b[39;00m images: \n",
      "\u001b[0;31mNameError\u001b[0m: name 'transform' is not defined"
     ]
    }
   ],
   "source": [
    "# Import library\n",
    "from pathlib import Path\n",
    "\n",
    "# Market1501 dataset dir\n",
    "raw_data_dir_market1501 = Path('/home/jun/ReID_Dataset/Market-1501-v15.09.15')\n",
    "# Make dictionary of all image market1501 with keys of image_name and values of image_path\n",
    "market_train_dic = {i.name:i for i in sorted(list(raw_data_dir_market1501.glob('bounding_box_train/*.jpg')))}\n",
    "market_gallery_dic = {i.name:i for i in sorted(list(raw_data_dir_market1501.glob('bounding_box_test/*.jpg')))}\n",
    "market_query_dic = {i.name:i for i in sorted(list(raw_data_dir_market1501.glob('query/*.jpg')))}\n",
    "\n",
    "import random\n",
    "\n",
    "# Assuming market_train_dic is already defined and populated with values\n",
    "image_paths_list = list(market_train_dic.values())\n",
    "\n",
    "# Shuffle the list to ensure randomness\n",
    "random.shuffle(image_paths_list)\n",
    "\n",
    "# Select 10 random paths\n",
    "random_image_paths = image_paths_list[:1]\n",
    "image_paths = list(market_train_dic.values())[200:201] \n",
    "#image_paths = random_image_paths\n",
    "\n",
    "images = list(transform(Image.open(image_path).convert('RGB')) for image_path in image_paths)  # Ensure image is in RGB mode\n",
    "# Apply the transformations\n",
    "#transformed_image = transforms(image)\n",
    "for image in images: \n",
    "\n",
    "    G_market_duke.eval()\n",
    "    G_duke_market.eval()\n",
    "    x = image.cuda()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        y1 = G_market_duke(x)\n",
    "        y2 = G_duke_market(x)\n",
    "    # Convert tensors to images\n",
    "    original_image_np = tensor_to_image(x.squeeze(0))  # Remove batch dimension for original image\n",
    "    output_image_np1 = tensor_to_image(y1)\n",
    "    output_image_np2 = tensor_to_image(y2)\n",
    "\n",
    "    # Display the images\n",
    "    plt.figure(figsize=(10, 5))\n",
    "\n",
    "    # Display the original image\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.title(\"Original Image\")\n",
    "    plt.imshow(original_image_np)\n",
    "    plt.axis('off')  # Hide the axes\n",
    "\n",
    "    # Display the output image\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.title(\"Style Transfered Image\")\n",
    "    plt.imshow(output_image_np1)\n",
    "    plt.axis('off')  # Hide the axes\n",
    "\n",
    "    # Display the output image\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.title(\"Generated Original Image\")\n",
    "    plt.imshow(output_image_np2)\n",
    "    plt.axis('off')  # Hide the axes\n",
    "    plt.show()\n",
    "\n",
    "# duke1501 dataset dir\n",
    "raw_data_dir_duke = Path('/home/jun/ReID_Dataset/DukeMTMC-reID')\n",
    "# Make dictionary of all image duke1501 with keys of image_name and values of image_path\n",
    "duke_train_dic = {i.name:i for i in sorted(list(raw_data_dir_duke.glob('bounding_box_train/*.jpg')))}\n",
    "duke_gallery_dic = {i.name:i for i in sorted(list(raw_data_dir_duke.glob('bounding_box_test/*.jpg')))}\n",
    "duke_query_dic = {i.name:i for i in sorted(list(raw_data_dir_duke.glob('query/*.jpg')))}\n",
    "\n",
    "import random\n",
    "\n",
    "# Assuming market_train_dic is already defined and populated with values\n",
    "image_paths_list = list(duke_train_dic.values())\n",
    "\n",
    "# Shuffle the list to ensure randomness\n",
    "random.shuffle(image_paths_list)\n",
    "\n",
    "# Select 10 random paths\n",
    "random_image_paths = image_paths_list[:1]\n",
    "image_paths = list(duke_train_dic.values())[200:201] \n",
    "#image_paths = random_image_paths\n",
    "\n",
    "images = list(transform(Image.open(image_path).convert('RGB')) for image_path in image_paths)  # Ensure image is in RGB mode\n",
    "# Apply the transformations\n",
    "#transformed_image = transforms(image)\n",
    "for image in images: \n",
    "\n",
    "    G_market_duke.eval()\n",
    "    G_duke_market.eval()\n",
    "    x = image.cuda()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        y2 = G_market_duke(x)\n",
    "        y1 = G_duke_market(x)\n",
    "    # Convert tensors to images\n",
    "    original_image_np = tensor_to_image(x.squeeze(0))  # Remove batch dimension for original image\n",
    "    output_image_np1 = tensor_to_image(y1)\n",
    "    output_image_np2 = tensor_to_image(y2)\n",
    "\n",
    "    # Display the images\n",
    "    plt.figure(figsize=(10, 5))\n",
    "\n",
    "    # Display the original image\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.title(\"Original Image\")\n",
    "    plt.imshow(original_image_np)\n",
    "    plt.axis('off')  # Hide the axes\n",
    "\n",
    "    # Display the output image\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.title(\"Style Transfered Image\")\n",
    "    plt.imshow(output_image_np1)\n",
    "    plt.axis('off')  # Hide the axes\n",
    "\n",
    "    # Display the output image\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.title(\"Generated Original Image\")\n",
    "    plt.imshow(output_image_np2)\n",
    "    plt.axis('off')  # Hide the axes\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data_dir_market1501 = Path('/home/jun/ReID_Dataset/Market-1501-v15.09.15-dukestyle-cycleGAN')\n",
    "new_data_dir_market1501.mkdir(exist_ok=True)\n",
    "new_market_train_dir = new_data_dir_market1501 / 'bounding_box_train'\n",
    "new_market_train_dir.mkdir(exist_ok=True)\n",
    "new_market_gallery_dir = new_data_dir_market1501 / 'bounding_box_test'\n",
    "new_market_gallery_dir.mkdir(exist_ok=True)\n",
    "new_market_query_dir = new_data_dir_market1501 / 'query'\n",
    "new_market_query_dir.mkdir(exist_ok=True)\n",
    "\n",
    "\n",
    "for image_name, image_path in market_train_dic.items():\n",
    "    image = Image.open(image_path).convert('RGB')  # Ensure image is in RGB mode\n",
    "    # Apply the transformations\n",
    "    transformed_image = transform(image)\n",
    "    G_market_duke.eval()\n",
    "    x = transformed_image.cuda()\n",
    "    with torch.no_grad():\n",
    "        y = G_market_duke(x)\n",
    "    output_image = tensor_to_image(y)\n",
    "    output_image = Image.fromarray(output_image)\n",
    "    output_image_path = new_market_train_dir / image_name\n",
    "    output_image.save(output_image_path)\n",
    "\n",
    "for image_name, image_path in market_gallery_dic.items():\n",
    "    image = Image.open(image_path).convert('RGB')  # Ensure image is in RGB mode\n",
    "    # Apply the transformations\n",
    "    transformed_image = transform(image)\n",
    "    G_market_duke.eval()\n",
    "    x = transformed_image.cuda()\n",
    "    with torch.no_grad():\n",
    "        y = G_market_duke(x)\n",
    "    output_image = tensor_to_image(y)\n",
    "    output_image = Image.fromarray(output_image)\n",
    "    output_image_path = new_market_gallery_dir / image_name\n",
    "    output_image.save(output_image_path)\n",
    "    \n",
    "for image_name, image_path in market_query_dic.items():\n",
    "    image = Image.open(image_path).convert('RGB')  # Ensure image is in RGB mode\n",
    "    # Apply the transformations\n",
    "    transformed_image = transform(image)\n",
    "    G_market_duke.eval()\n",
    "    x = transformed_image.cuda()\n",
    "    with torch.no_grad():\n",
    "        y = G_market_duke(x)\n",
    "    output_image = tensor_to_image(y)\n",
    "    output_image = Image.fromarray(output_image)\n",
    "    output_image_path = new_market_query_dir / image_name\n",
    "    output_image.save(output_image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import library\n",
    "from pathlib import Path\n",
    "\n",
    "# duke1501 dataset dir\n",
    "raw_data_dir_duke = Path('/home/jun/ReID_Dataset/DukeMTMC-reID')\n",
    "# Make dictionary of all image duke1501 with keys of image_name and values of image_path\n",
    "duke_train_dic = {i.name:i for i in sorted(list(raw_data_dir_duke.glob('bounding_box_train/*.jpg')))}\n",
    "duke_gallery_dic = {i.name:i for i in sorted(list(raw_data_dir_duke.glob('bounding_box_test/*.jpg')))}\n",
    "duke_query_dic = {i.name:i for i in sorted(list(raw_data_dir_duke.glob('query/*.jpg')))}\n",
    "\n",
    "new_data_dir_duke = Path('/home/jun/ReID_Dataset/DukeMTMC-reID-marketstyle-cycleGAN')\n",
    "new_data_dir_duke.mkdir(exist_ok=True)\n",
    "new_duke_train_dir = new_data_dir_duke / 'bounding_box_train'\n",
    "new_duke_train_dir.mkdir(exist_ok=True)\n",
    "new_duke_gallery_dir = new_data_dir_duke / 'bounding_box_test'\n",
    "new_duke_gallery_dir.mkdir(exist_ok=True)\n",
    "new_duke_query_dir = new_data_dir_duke / 'query'\n",
    "new_duke_query_dir.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jun/miniconda3/envs/py312/lib/python3.12/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at /opt/conda/conda-bld/pytorch_1712608847532/work/aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "for image_name, image_path in duke_train_dic.items():\n",
    "    image = Image.open(image_path).convert('RGB')  # Ensure image is in RGB mode\n",
    "    # Apply the transformations\n",
    "    transformed_image = transform(image)\n",
    "    G_duke_market.eval()\n",
    "    x = transformed_image.cuda()\n",
    "    with torch.no_grad():\n",
    "        y = G_duke_market(x)\n",
    "    output_image = tensor_to_image(y)\n",
    "    output_image = Image.fromarray(output_image)\n",
    "    output_image_path = new_duke_train_dir / image_name\n",
    "    output_image.save(output_image_path)\n",
    "\n",
    "for image_name, image_path in duke_gallery_dic.items():\n",
    "    image = Image.open(image_path).convert('RGB')  # Ensure image is in RGB mode\n",
    "    # Apply the transformations\n",
    "    transformed_image = transform(image)\n",
    "    G_duke_market.eval()\n",
    "    x = transformed_image.cuda()\n",
    "    with torch.no_grad():\n",
    "        y = G_duke_market(x)\n",
    "    output_image = tensor_to_image(y)\n",
    "    output_image = Image.fromarray(output_image)\n",
    "    output_image_path = new_duke_gallery_dir / image_name\n",
    "    output_image.save(output_image_path)\n",
    "    \n",
    "for image_name, image_path in duke_query_dic.items():\n",
    "    image = Image.open(image_path).convert('RGB')  # Ensure image is in RGB mode\n",
    "    # Apply the transformations\n",
    "    transformed_image = transform(image)\n",
    "    G_duke_market.eval()\n",
    "    x = transformed_image.cuda()\n",
    "    with torch.no_grad():\n",
    "        y = G_duke_market(x)\n",
    "    output_image = tensor_to_image(y)\n",
    "    output_image = Image.fromarray(output_image)\n",
    "    output_image_path = new_duke_query_dir / image_name\n",
    "    output_image.save(output_image_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
