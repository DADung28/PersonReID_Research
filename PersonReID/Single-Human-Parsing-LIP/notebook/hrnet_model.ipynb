{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import numpy as np\n",
    "from config.default import _C as config\n",
    "from config.default import update_config\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from solver import make_optimizer, WarmupMultiStepLR\n",
    "from dataset.lip import LIPWithClass_Binary, LIPWithClass, LIPWithClass_Six\n",
    "from net.pspnet import PSPNet\n",
    "from hrnet.seg_hrnet import HighResolutionNet\n",
    "from torchinfo import summary\n",
    "from torchview import draw_graph\n",
    "from torch.nn import functional as F\n",
    "parser = argparse.ArgumentParser(description=\"Human Parsing\")\n",
    "parser.add_argument('--cfg',\n",
    "                        default='config_yml/seg_hrnet_w48.yaml',\n",
    "                        help='experiment configure file name',\n",
    "                        type=str)\n",
    "parser.add_argument('opts',\n",
    "                        help=\"Modify config options using the command-line\",\n",
    "                        default=None,\n",
    "                        nargs=argparse.REMAINDER)\n",
    "parser.add_argument('--data_path', type=str, default='/home/jun/HumanSemanticDataset/myLIP')\n",
    "parser.add_argument('--backend', type=str, default='densenet', help='Feature extractor')\n",
    "parser.add_argument('--snapshot', type=str, default=None, help='Path to pre-trained weights')\n",
    "parser.add_argument('--batch_size', type=int, default=16, help=\"Number of images sent to the network in one step.\")\n",
    "parser.add_argument('--epochs', type=int, default=40, help='Number of training epochs to run')\n",
    "parser.add_argument('--crop_x', type=int, default=224, help='Horizontal random crop size')\n",
    "parser.add_argument('--crop_y', type=int, default=224, help='Vertical random crop size')\n",
    "parser.add_argument('--alpha', type=float, default=1.0, help='Coefficient for classification loss term')\n",
    "parser.add_argument('--start_lr', type=float, default=0.0001, help='Learning rate')\n",
    "parser.add_argument('--milestones', type=str, default='10,20,30', help='Milestones for LR decreasing')\n",
    "parser.add_argument('--mode', type=str, default='all', help='Traing model: all, binary, six')\n",
    "parser.add_argument('--gpu', type=int, default=0, help='List of GPUs for parallel training, e.g. 0,1,2,3')\n",
    "\n",
    "args = parser.parse_args([])\n",
    "update_config(config, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seg_hrnet\n"
     ]
    }
   ],
   "source": [
    "print(config.MODEL.NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_seg_model(cfg, **kwargs):\n",
    "    model = HighResolutionNet(cfg, **kwargs)\n",
    "    model.init_weights(cfg.MODEL.PRETRAINED)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_seg_model(config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PSPNet(nn.Module):\n",
    "    def __init__(self, cfg, **kwargs):\n",
    "        super().__init__()\n",
    "        model = HighResolutionNet(cfg)\n",
    "        #model.load_state_dict(torch.load(cfg.MODEL.PRETRAINED))\n",
    "        model.init_weights(cfg.MODEL.PRETRAINED)\n",
    "        self.model = model\n",
    "        self.interpolate = nn.functional.interpolate\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        x = self.interpolate(input=x, size=(512, 512), mode='bilinear', align_corners=config.MODEL.ALIGN_CORNERS)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for HighResolutionNet:\n\tMissing key(s) in state_dict: \"last_layer.0.weight\", \"last_layer.0.bias\", \"last_layer.1.weight\", \"last_layer.1.bias\", \"last_layer.1.running_mean\", \"last_layer.1.running_var\", \"last_layer.3.weight\", \"last_layer.3.bias\". \n\tUnexpected key(s) in state_dict: \"incre_modules.0.0.conv1.weight\", \"incre_modules.0.0.bn1.weight\", \"incre_modules.0.0.bn1.bias\", \"incre_modules.0.0.bn1.running_mean\", \"incre_modules.0.0.bn1.running_var\", \"incre_modules.0.0.bn1.num_batches_tracked\", \"incre_modules.0.0.conv2.weight\", \"incre_modules.0.0.bn2.weight\", \"incre_modules.0.0.bn2.bias\", \"incre_modules.0.0.bn2.running_mean\", \"incre_modules.0.0.bn2.running_var\", \"incre_modules.0.0.bn2.num_batches_tracked\", \"incre_modules.0.0.conv3.weight\", \"incre_modules.0.0.bn3.weight\", \"incre_modules.0.0.bn3.bias\", \"incre_modules.0.0.bn3.running_mean\", \"incre_modules.0.0.bn3.running_var\", \"incre_modules.0.0.bn3.num_batches_tracked\", \"incre_modules.0.0.downsample.0.weight\", \"incre_modules.0.0.downsample.1.weight\", \"incre_modules.0.0.downsample.1.bias\", \"incre_modules.0.0.downsample.1.running_mean\", \"incre_modules.0.0.downsample.1.running_var\", \"incre_modules.0.0.downsample.1.num_batches_tracked\", \"incre_modules.1.0.conv1.weight\", \"incre_modules.1.0.bn1.weight\", \"incre_modules.1.0.bn1.bias\", \"incre_modules.1.0.bn1.running_mean\", \"incre_modules.1.0.bn1.running_var\", \"incre_modules.1.0.bn1.num_batches_tracked\", \"incre_modules.1.0.conv2.weight\", \"incre_modules.1.0.bn2.weight\", \"incre_modules.1.0.bn2.bias\", \"incre_modules.1.0.bn2.running_mean\", \"incre_modules.1.0.bn2.running_var\", \"incre_modules.1.0.bn2.num_batches_tracked\", \"incre_modules.1.0.conv3.weight\", \"incre_modules.1.0.bn3.weight\", \"incre_modules.1.0.bn3.bias\", \"incre_modules.1.0.bn3.running_mean\", \"incre_modules.1.0.bn3.running_var\", \"incre_modules.1.0.bn3.num_batches_tracked\", \"incre_modules.1.0.downsample.0.weight\", \"incre_modules.1.0.downsample.1.weight\", \"incre_modules.1.0.downsample.1.bias\", \"incre_modules.1.0.downsample.1.running_mean\", \"incre_modules.1.0.downsample.1.running_var\", \"incre_modules.1.0.downsample.1.num_batches_tracked\", \"incre_modules.2.0.conv1.weight\", \"incre_modules.2.0.bn1.weight\", \"incre_modules.2.0.bn1.bias\", \"incre_modules.2.0.bn1.running_mean\", \"incre_modules.2.0.bn1.running_var\", \"incre_modules.2.0.bn1.num_batches_tracked\", \"incre_modules.2.0.conv2.weight\", \"incre_modules.2.0.bn2.weight\", \"incre_modules.2.0.bn2.bias\", \"incre_modules.2.0.bn2.running_mean\", \"incre_modules.2.0.bn2.running_var\", \"incre_modules.2.0.bn2.num_batches_tracked\", \"incre_modules.2.0.conv3.weight\", \"incre_modules.2.0.bn3.weight\", \"incre_modules.2.0.bn3.bias\", \"incre_modules.2.0.bn3.running_mean\", \"incre_modules.2.0.bn3.running_var\", \"incre_modules.2.0.bn3.num_batches_tracked\", \"incre_modules.2.0.downsample.0.weight\", \"incre_modules.2.0.downsample.1.weight\", \"incre_modules.2.0.downsample.1.bias\", \"incre_modules.2.0.downsample.1.running_mean\", \"incre_modules.2.0.downsample.1.running_var\", \"incre_modules.2.0.downsample.1.num_batches_tracked\", \"incre_modules.3.0.conv1.weight\", \"incre_modules.3.0.bn1.weight\", \"incre_modules.3.0.bn1.bias\", \"incre_modules.3.0.bn1.running_mean\", \"incre_modules.3.0.bn1.running_var\", \"incre_modules.3.0.bn1.num_batches_tracked\", \"incre_modules.3.0.conv2.weight\", \"incre_modules.3.0.bn2.weight\", \"incre_modules.3.0.bn2.bias\", \"incre_modules.3.0.bn2.running_mean\", \"incre_modules.3.0.bn2.running_var\", \"incre_modules.3.0.bn2.num_batches_tracked\", \"incre_modules.3.0.conv3.weight\", \"incre_modules.3.0.bn3.weight\", \"incre_modules.3.0.bn3.bias\", \"incre_modules.3.0.bn3.running_mean\", \"incre_modules.3.0.bn3.running_var\", \"incre_modules.3.0.bn3.num_batches_tracked\", \"incre_modules.3.0.downsample.0.weight\", \"incre_modules.3.0.downsample.1.weight\", \"incre_modules.3.0.downsample.1.bias\", \"incre_modules.3.0.downsample.1.running_mean\", \"incre_modules.3.0.downsample.1.running_var\", \"incre_modules.3.0.downsample.1.num_batches_tracked\", \"downsamp_modules.0.0.weight\", \"downsamp_modules.0.0.bias\", \"downsamp_modules.0.1.weight\", \"downsamp_modules.0.1.bias\", \"downsamp_modules.0.1.running_mean\", \"downsamp_modules.0.1.running_var\", \"downsamp_modules.0.1.num_batches_tracked\", \"downsamp_modules.1.0.weight\", \"downsamp_modules.1.0.bias\", \"downsamp_modules.1.1.weight\", \"downsamp_modules.1.1.bias\", \"downsamp_modules.1.1.running_mean\", \"downsamp_modules.1.1.running_var\", \"downsamp_modules.1.1.num_batches_tracked\", \"downsamp_modules.2.0.weight\", \"downsamp_modules.2.0.bias\", \"downsamp_modules.2.1.weight\", \"downsamp_modules.2.1.bias\", \"downsamp_modules.2.1.running_mean\", \"downsamp_modules.2.1.running_var\", \"downsamp_modules.2.1.num_batches_tracked\", \"final_layer.0.weight\", \"final_layer.0.bias\", \"final_layer.1.weight\", \"final_layer.1.bias\", \"final_layer.1.running_mean\", \"final_layer.1.running_var\", \"final_layer.1.num_batches_tracked\", \"classifier.weight\", \"classifier.bias\". ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m PSPNet(config)\n",
      "Cell \u001b[0;32mIn[5], line 5\u001b[0m, in \u001b[0;36mPSPNet.__init__\u001b[0;34m(self, cfg, **kwargs)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n\u001b[1;32m      4\u001b[0m model \u001b[38;5;241m=\u001b[39m HighResolutionNet(cfg)\n\u001b[0;32m----> 5\u001b[0m model\u001b[38;5;241m.\u001b[39mload_state_dict(torch\u001b[38;5;241m.\u001b[39mload(cfg\u001b[38;5;241m.\u001b[39mMODEL\u001b[38;5;241m.\u001b[39mPRETRAINED))\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m#model.init_weights(cfg.MODEL.PRETRAINED)\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m model\n",
      "File \u001b[0;32m~/miniconda3/envs/py311/lib/python3.11/site-packages/torch/nn/modules/module.py:2152\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[1;32m   2147\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[1;32m   2148\u001b[0m             \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2149\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)))\n\u001b[1;32m   2151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 2152\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2153\u001b[0m                        \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)))\n\u001b[1;32m   2154\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for HighResolutionNet:\n\tMissing key(s) in state_dict: \"last_layer.0.weight\", \"last_layer.0.bias\", \"last_layer.1.weight\", \"last_layer.1.bias\", \"last_layer.1.running_mean\", \"last_layer.1.running_var\", \"last_layer.3.weight\", \"last_layer.3.bias\". \n\tUnexpected key(s) in state_dict: \"incre_modules.0.0.conv1.weight\", \"incre_modules.0.0.bn1.weight\", \"incre_modules.0.0.bn1.bias\", \"incre_modules.0.0.bn1.running_mean\", \"incre_modules.0.0.bn1.running_var\", \"incre_modules.0.0.bn1.num_batches_tracked\", \"incre_modules.0.0.conv2.weight\", \"incre_modules.0.0.bn2.weight\", \"incre_modules.0.0.bn2.bias\", \"incre_modules.0.0.bn2.running_mean\", \"incre_modules.0.0.bn2.running_var\", \"incre_modules.0.0.bn2.num_batches_tracked\", \"incre_modules.0.0.conv3.weight\", \"incre_modules.0.0.bn3.weight\", \"incre_modules.0.0.bn3.bias\", \"incre_modules.0.0.bn3.running_mean\", \"incre_modules.0.0.bn3.running_var\", \"incre_modules.0.0.bn3.num_batches_tracked\", \"incre_modules.0.0.downsample.0.weight\", \"incre_modules.0.0.downsample.1.weight\", \"incre_modules.0.0.downsample.1.bias\", \"incre_modules.0.0.downsample.1.running_mean\", \"incre_modules.0.0.downsample.1.running_var\", \"incre_modules.0.0.downsample.1.num_batches_tracked\", \"incre_modules.1.0.conv1.weight\", \"incre_modules.1.0.bn1.weight\", \"incre_modules.1.0.bn1.bias\", \"incre_modules.1.0.bn1.running_mean\", \"incre_modules.1.0.bn1.running_var\", \"incre_modules.1.0.bn1.num_batches_tracked\", \"incre_modules.1.0.conv2.weight\", \"incre_modules.1.0.bn2.weight\", \"incre_modules.1.0.bn2.bias\", \"incre_modules.1.0.bn2.running_mean\", \"incre_modules.1.0.bn2.running_var\", \"incre_modules.1.0.bn2.num_batches_tracked\", \"incre_modules.1.0.conv3.weight\", \"incre_modules.1.0.bn3.weight\", \"incre_modules.1.0.bn3.bias\", \"incre_modules.1.0.bn3.running_mean\", \"incre_modules.1.0.bn3.running_var\", \"incre_modules.1.0.bn3.num_batches_tracked\", \"incre_modules.1.0.downsample.0.weight\", \"incre_modules.1.0.downsample.1.weight\", \"incre_modules.1.0.downsample.1.bias\", \"incre_modules.1.0.downsample.1.running_mean\", \"incre_modules.1.0.downsample.1.running_var\", \"incre_modules.1.0.downsample.1.num_batches_tracked\", \"incre_modules.2.0.conv1.weight\", \"incre_modules.2.0.bn1.weight\", \"incre_modules.2.0.bn1.bias\", \"incre_modules.2.0.bn1.running_mean\", \"incre_modules.2.0.bn1.running_var\", \"incre_modules.2.0.bn1.num_batches_tracked\", \"incre_modules.2.0.conv2.weight\", \"incre_modules.2.0.bn2.weight\", \"incre_modules.2.0.bn2.bias\", \"incre_modules.2.0.bn2.running_mean\", \"incre_modules.2.0.bn2.running_var\", \"incre_modules.2.0.bn2.num_batches_tracked\", \"incre_modules.2.0.conv3.weight\", \"incre_modules.2.0.bn3.weight\", \"incre_modules.2.0.bn3.bias\", \"incre_modules.2.0.bn3.running_mean\", \"incre_modules.2.0.bn3.running_var\", \"incre_modules.2.0.bn3.num_batches_tracked\", \"incre_modules.2.0.downsample.0.weight\", \"incre_modules.2.0.downsample.1.weight\", \"incre_modules.2.0.downsample.1.bias\", \"incre_modules.2.0.downsample.1.running_mean\", \"incre_modules.2.0.downsample.1.running_var\", \"incre_modules.2.0.downsample.1.num_batches_tracked\", \"incre_modules.3.0.conv1.weight\", \"incre_modules.3.0.bn1.weight\", \"incre_modules.3.0.bn1.bias\", \"incre_modules.3.0.bn1.running_mean\", \"incre_modules.3.0.bn1.running_var\", \"incre_modules.3.0.bn1.num_batches_tracked\", \"incre_modules.3.0.conv2.weight\", \"incre_modules.3.0.bn2.weight\", \"incre_modules.3.0.bn2.bias\", \"incre_modules.3.0.bn2.running_mean\", \"incre_modules.3.0.bn2.running_var\", \"incre_modules.3.0.bn2.num_batches_tracked\", \"incre_modules.3.0.conv3.weight\", \"incre_modules.3.0.bn3.weight\", \"incre_modules.3.0.bn3.bias\", \"incre_modules.3.0.bn3.running_mean\", \"incre_modules.3.0.bn3.running_var\", \"incre_modules.3.0.bn3.num_batches_tracked\", \"incre_modules.3.0.downsample.0.weight\", \"incre_modules.3.0.downsample.1.weight\", \"incre_modules.3.0.downsample.1.bias\", \"incre_modules.3.0.downsample.1.running_mean\", \"incre_modules.3.0.downsample.1.running_var\", \"incre_modules.3.0.downsample.1.num_batches_tracked\", \"downsamp_modules.0.0.weight\", \"downsamp_modules.0.0.bias\", \"downsamp_modules.0.1.weight\", \"downsamp_modules.0.1.bias\", \"downsamp_modules.0.1.running_mean\", \"downsamp_modules.0.1.running_var\", \"downsamp_modules.0.1.num_batches_tracked\", \"downsamp_modules.1.0.weight\", \"downsamp_modules.1.0.bias\", \"downsamp_modules.1.1.weight\", \"downsamp_modules.1.1.bias\", \"downsamp_modules.1.1.running_mean\", \"downsamp_modules.1.1.running_var\", \"downsamp_modules.1.1.num_batches_tracked\", \"downsamp_modules.2.0.weight\", \"downsamp_modules.2.0.bias\", \"downsamp_modules.2.1.weight\", \"downsamp_modules.2.1.bias\", \"downsamp_modules.2.1.running_mean\", \"downsamp_modules.2.1.running_var\", \"downsamp_modules.2.1.num_batches_tracked\", \"final_layer.0.weight\", \"final_layer.0.bias\", \"final_layer.1.weight\", \"final_layer.1.bias\", \"final_layer.1.running_mean\", \"final_layer.1.running_var\", \"final_layer.1.num_batches_tracked\", \"classifier.weight\", \"classifier.bias\". "
     ]
    }
   ],
   "source": [
    "model = PSPNet(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 6, 512, 512])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "============================================================================================================================================\n",
       "Layer (type (var_name))                                      Input Shape          Output Shape         Param #              Trainable\n",
       "============================================================================================================================================\n",
       "PSPNet (PSPNet)                                              [32, 3, 512, 512]    [32, 6, 512, 512]    --                   True\n",
       "├─HighResolutionNet (model)                                  [32, 3, 512, 512]    [32, 6, 128, 128]    --                   True\n",
       "│    └─Conv2d (conv1)                                        [32, 3, 512, 512]    [32, 64, 256, 256]   1,728                True\n",
       "│    └─SyncBatchNorm (bn1)                                   [32, 64, 256, 256]   [32, 64, 256, 256]   128                  True\n",
       "│    └─ReLU (relu)                                           [32, 64, 256, 256]   [32, 64, 256, 256]   --                   --\n",
       "│    └─Conv2d (conv2)                                        [32, 64, 256, 256]   [32, 64, 128, 128]   36,864               True\n",
       "│    └─SyncBatchNorm (bn2)                                   [32, 64, 128, 128]   [32, 64, 128, 128]   128                  True\n",
       "│    └─ReLU (relu)                                           [32, 64, 128, 128]   [32, 64, 128, 128]   --                   --\n",
       "│    └─Sequential (layer1)                                   [32, 64, 128, 128]   [32, 256, 128, 128]  --                   True\n",
       "│    │    └─Bottleneck (0)                                   [32, 64, 128, 128]   [32, 256, 128, 128]  75,008               True\n",
       "│    │    └─Bottleneck (1)                                   [32, 256, 128, 128]  [32, 256, 128, 128]  70,400               True\n",
       "│    │    └─Bottleneck (2)                                   [32, 256, 128, 128]  [32, 256, 128, 128]  70,400               True\n",
       "│    │    └─Bottleneck (3)                                   [32, 256, 128, 128]  [32, 256, 128, 128]  70,400               True\n",
       "│    └─ModuleList (transition1)                              --                   --                   --                   True\n",
       "│    │    └─Sequential (0)                                   [32, 256, 128, 128]  [32, 48, 128, 128]   110,688              True\n",
       "│    │    └─Sequential (1)                                   [32, 256, 128, 128]  [32, 96, 64, 64]     221,376              True\n",
       "│    └─Sequential (stage2)                                   [32, 48, 128, 128]   [32, 48, 128, 128]   --                   True\n",
       "│    │    └─HighResolutionModule (0)                         [32, 48, 128, 128]   [32, 48, 128, 128]   878,112              True\n",
       "│    └─ModuleList (transition2)                              --                   --                   --                   True\n",
       "│    │    └─Sequential (2)                                   [32, 96, 64, 64]     [32, 192, 32, 32]    166,272              True\n",
       "│    └─Sequential (stage3)                                   [32, 48, 128, 128]   [32, 48, 128, 128]   --                   True\n",
       "│    │    └─HighResolutionModule (0)                         [32, 48, 128, 128]   [32, 48, 128, 128]   3,833,760            True\n",
       "│    │    └─HighResolutionModule (1)                         [32, 48, 128, 128]   [32, 48, 128, 128]   3,833,760            True\n",
       "│    │    └─HighResolutionModule (2)                         [32, 48, 128, 128]   [32, 48, 128, 128]   3,833,760            True\n",
       "│    │    └─HighResolutionModule (3)                         [32, 48, 128, 128]   [32, 48, 128, 128]   3,833,760            True\n",
       "│    └─ModuleList (transition3)                              --                   --                   --                   True\n",
       "│    │    └─Sequential (3)                                   [32, 192, 32, 32]    [32, 384, 16, 16]    664,320              True\n",
       "│    └─Sequential (stage4)                                   [32, 48, 128, 128]   [32, 48, 128, 128]   --                   True\n",
       "│    │    └─HighResolutionModule (0)                         [32, 48, 128, 128]   [32, 48, 128, 128]   15,874,752           True\n",
       "│    │    └─HighResolutionModule (1)                         [32, 48, 128, 128]   [32, 48, 128, 128]   15,874,752           True\n",
       "│    │    └─HighResolutionModule (2)                         [32, 48, 128, 128]   [32, 48, 128, 128]   15,874,752           True\n",
       "│    └─Sequential (last_layer)                               [32, 720, 128, 128]  [32, 6, 128, 128]    --                   True\n",
       "│    │    └─Conv2d (0)                                       [32, 720, 128, 128]  [32, 720, 128, 128]  519,120              True\n",
       "│    │    └─SyncBatchNorm (1)                                [32, 720, 128, 128]  [32, 720, 128, 128]  1,440                True\n",
       "│    │    └─ReLU (2)                                         [32, 720, 128, 128]  [32, 720, 128, 128]  --                   --\n",
       "│    │    └─Conv2d (3)                                       [32, 720, 128, 128]  [32, 6, 128, 128]    4,326                True\n",
       "============================================================================================================================================\n",
       "Total params: 65,850,006\n",
       "Trainable params: 65,850,006\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.TERABYTES): 2.99\n",
       "============================================================================================================================================\n",
       "Input size (MB): 100.66\n",
       "Forward/backward pass size (MB): 76208.41\n",
       "Params size (MB): 263.40\n",
       "Estimated Total Size (MB): 76572.47\n",
       "============================================================================================================================================"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model=model, \n",
    "        input_size=(32, 3, 512, 512), # make sure this is \"input_size\", not \"input_shape\"\n",
    "        # col_names=[\"input_size\"], # uncomment for smaller output\n",
    "        col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
    "        col_width=20,\n",
    "        row_settings=[\"var_names\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 6, 512, 512])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[[-2.7439e-02, -2.7439e-02, -2.8130e-02,  ..., -2.2990e-02,\n",
       "           -2.2533e-02, -2.2533e-02],\n",
       "          [-2.7439e-02, -2.7439e-02, -2.8130e-02,  ..., -2.2990e-02,\n",
       "           -2.2533e-02, -2.2533e-02],\n",
       "          [-2.7083e-02, -2.7083e-02, -2.7920e-02,  ..., -2.2779e-02,\n",
       "           -2.2413e-02, -2.2413e-02],\n",
       "          ...,\n",
       "          [-2.5058e-02, -2.5058e-02, -2.5725e-02,  ..., -1.0139e-02,\n",
       "           -1.0411e-02, -1.0411e-02],\n",
       "          [-2.4665e-02, -2.4665e-02, -2.5305e-02,  ..., -9.9808e-03,\n",
       "           -1.0179e-02, -1.0179e-02],\n",
       "          [-2.4665e-02, -2.4665e-02, -2.5305e-02,  ..., -9.9808e-03,\n",
       "           -1.0179e-02, -1.0179e-02]],\n",
       "\n",
       "         [[-6.9374e-03, -6.9374e-03, -6.2066e-03,  ...,  1.9447e-02,\n",
       "            1.9487e-02,  1.9487e-02],\n",
       "          [-6.9374e-03, -6.9374e-03, -6.2066e-03,  ...,  1.9447e-02,\n",
       "            1.9487e-02,  1.9487e-02],\n",
       "          [-6.6734e-03, -6.6734e-03, -5.7807e-03,  ...,  1.9012e-02,\n",
       "            1.8878e-02,  1.8878e-02],\n",
       "          ...,\n",
       "          [ 2.5977e-03,  2.5977e-03,  2.3417e-03,  ...,  9.2497e-03,\n",
       "            8.2128e-03,  8.2128e-03],\n",
       "          [ 2.5494e-03,  2.5494e-03,  2.2460e-03,  ...,  9.5739e-03,\n",
       "            8.4562e-03,  8.4562e-03],\n",
       "          [ 2.5494e-03,  2.5494e-03,  2.2460e-03,  ...,  9.5739e-03,\n",
       "            8.4562e-03,  8.4562e-03]],\n",
       "\n",
       "         [[ 1.2272e-03,  1.2272e-03,  1.3237e-03,  ...,  3.7011e-03,\n",
       "            2.8913e-03,  2.8913e-03],\n",
       "          [ 1.2272e-03,  1.2272e-03,  1.3237e-03,  ...,  3.7011e-03,\n",
       "            2.8913e-03,  2.8913e-03],\n",
       "          [ 1.9125e-03,  1.9125e-03,  1.9229e-03,  ...,  4.3006e-03,\n",
       "            3.7031e-03,  3.7031e-03],\n",
       "          ...,\n",
       "          [-6.7747e-03, -6.7747e-03, -6.5585e-03,  ...,  1.3895e-02,\n",
       "            1.3510e-02,  1.3510e-02],\n",
       "          [-6.0152e-03, -6.0152e-03, -5.7481e-03,  ...,  1.3257e-02,\n",
       "            1.2744e-02,  1.2744e-02],\n",
       "          [-6.0152e-03, -6.0152e-03, -5.7481e-03,  ...,  1.3257e-02,\n",
       "            1.2744e-02,  1.2744e-02]],\n",
       "\n",
       "         [[-1.3225e-05, -1.3225e-05, -5.2816e-04,  ..., -6.7259e-03,\n",
       "           -6.3212e-03, -6.3212e-03],\n",
       "          [-1.3225e-05, -1.3225e-05, -5.2816e-04,  ..., -6.7259e-03,\n",
       "           -6.3212e-03, -6.3212e-03],\n",
       "          [ 1.2705e-03,  1.2705e-03,  6.4710e-04,  ..., -6.7521e-03,\n",
       "           -6.5500e-03, -6.5500e-03],\n",
       "          ...,\n",
       "          [ 2.4635e-02,  2.4635e-02,  2.4965e-02,  ..., -2.6959e-02,\n",
       "           -2.7857e-02, -2.7857e-02],\n",
       "          [ 2.4790e-02,  2.4790e-02,  2.5236e-02,  ..., -2.7415e-02,\n",
       "           -2.8188e-02, -2.8188e-02],\n",
       "          [ 2.4790e-02,  2.4790e-02,  2.5236e-02,  ..., -2.7415e-02,\n",
       "           -2.8188e-02, -2.8188e-02]],\n",
       "\n",
       "         [[-1.7004e-02, -1.7004e-02, -1.6312e-02,  ..., -1.7898e-02,\n",
       "           -1.7634e-02, -1.7634e-02],\n",
       "          [-1.7004e-02, -1.7004e-02, -1.6312e-02,  ..., -1.7898e-02,\n",
       "           -1.7634e-02, -1.7634e-02],\n",
       "          [-1.7155e-02, -1.7155e-02, -1.6499e-02,  ..., -1.7600e-02,\n",
       "           -1.7239e-02, -1.7239e-02],\n",
       "          ...,\n",
       "          [-1.2703e-02, -1.2703e-02, -1.2089e-02,  ...,  2.4716e-03,\n",
       "            1.8158e-03,  1.8158e-03],\n",
       "          [-1.1713e-02, -1.1713e-02, -1.0989e-02,  ...,  2.3805e-03,\n",
       "            1.5532e-03,  1.5532e-03],\n",
       "          [-1.1713e-02, -1.1713e-02, -1.0989e-02,  ...,  2.3805e-03,\n",
       "            1.5532e-03,  1.5532e-03]],\n",
       "\n",
       "         [[-1.1896e-02, -1.1896e-02, -1.1473e-02,  ...,  1.6846e-02,\n",
       "            1.6917e-02,  1.6917e-02],\n",
       "          [-1.1896e-02, -1.1896e-02, -1.1473e-02,  ...,  1.6846e-02,\n",
       "            1.6917e-02,  1.6917e-02],\n",
       "          [-1.3325e-02, -1.3325e-02, -1.2914e-02,  ...,  1.7029e-02,\n",
       "            1.7248e-02,  1.7248e-02],\n",
       "          ...,\n",
       "          [ 1.0693e-02,  1.0693e-02,  1.0409e-02,  ..., -3.4034e-03,\n",
       "           -2.6341e-03, -2.6341e-03],\n",
       "          [ 1.2370e-02,  1.2370e-02,  1.1960e-02,  ..., -2.5432e-03,\n",
       "           -1.7561e-03, -1.7561e-03],\n",
       "          [ 1.2370e-02,  1.2370e-02,  1.1960e-02,  ..., -2.5432e-03,\n",
       "           -1.7561e-03, -1.7561e-03]]]], device='cuda:0',\n",
       "       grad_fn=<UpsampleBilinear2DBackward0>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "x = torch.randn(1, 3, 512, 512).to('cuda')\n",
    "model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = draw_graph(model, x)\n",
    "#graph.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FullModel(nn.Module):\n",
    "  \"\"\"\n",
    "  Distribute the loss on multi-gpu to reduce \n",
    "  the memory cost in the main gpu.\n",
    "  You can check the following discussion.\n",
    "  https://discuss.pytorch.org/t/dataparallel-imbalanced-memory-usage/22551/21\n",
    "  \"\"\"\n",
    "  def __init__(self, model, loss):\n",
    "    super(FullModel, self).__init__()\n",
    "    self.model = model\n",
    "    self.loss = loss\n",
    "\n",
    "  def forward(self, inputs, labels, *args, **kwargs):\n",
    "    outputs = self.model(inputs, *args, **kwargs)\n",
    "    loss = self.loss(outputs, labels)\n",
    "    return torch.unsqueeze(loss,0), outputs\n",
    "\n",
    "class CrossEntropy(nn.Module):\n",
    "    def __init__(self, ignore_label=-1, weight=None):\n",
    "        super(CrossEntropy, self).__init__()\n",
    "        self.ignore_label = ignore_label\n",
    "        self.criterion = nn.CrossEntropyLoss(\n",
    "            weight=weight,\n",
    "            ignore_index=ignore_label\n",
    "        )\n",
    "\n",
    "    def _forward(self, score, target):\n",
    "        ph, pw = score.size(2), score.size(3)\n",
    "        h, w = target.size(1), target.size(2)\n",
    "        if ph != h or pw != w:\n",
    "            score = F.interpolate(input=score, size=(\n",
    "                h, w), mode='bilinear', align_corners=config.MODEL.ALIGN_CORNERS)\n",
    "\n",
    "        loss = self.criterion(score, target)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def forward(self, score, target):\n",
    "\n",
    "        if config.MODEL.NUM_OUTPUTS == 1:\n",
    "            score = [score]\n",
    "\n",
    "        weights = config.LOSS.BALANCE_WEIGHTS\n",
    "        assert len(weights) == len(score)\n",
    "\n",
    "        return sum([w * self._forward(x, target) for (w, x) in zip(weights, score)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = CrossEntropy(ignore_label=config.TRAIN.IGNORE_LABEL, weight=train_dataset.class_weights)\n",
    "model = FullModel(model, criterion)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
