{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import os\n",
    "import torch\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import re\n",
    "sample_dir = './all_visualize'\n",
    "os.makedirs(sample_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def person_cam_split(dataset_path, cam_num):\n",
    "    image_paths = sorted(list(dataset_path.glob('bounding_box_train/*.jpg')))\n",
    "    person = {} # {id : {0: [cam0_list], 1: [cam1_list], ... }\n",
    "    for image_path in image_paths:\n",
    "        image_name = image_path.name\n",
    "        person_id = image_name.split('_')[0]\n",
    "        cam_id = int(image_name.split('_')[1][1]) - 1\n",
    "        if person_id in person.keys():\n",
    "            if cam_id in person[person_id].keys():\n",
    "                person[person_id][cam_id].append(image_path)\n",
    "            else:\n",
    "                person[person_id][cam_id] = [image_path]\n",
    "        else:\n",
    "            person[person_id] = {}\n",
    "            person[person_id][cam_id] = [image_path]\n",
    "    return person\n",
    "\n",
    "def cam_filter(person_dic, cam_num):\n",
    "    full_cam = {}\n",
    "    for person_id, all_cam in person_dic.items():\n",
    "        if len(all_cam) == cam_num:\n",
    "            full_cam[person_id] = all_cam\n",
    "    return full_cam\n",
    "\n",
    "def cam_split(dataset_path, cam_num):\n",
    "    image_paths = sorted(list(dataset_path.glob('bounding_box_train/*.jpg')))\n",
    "    cam_list = []\n",
    "    for i in range(cam_num):\n",
    "        cam_list.append([])\n",
    "    for image_path in image_paths:\n",
    "        image_name = image_path.name\n",
    "        cam_id = int(image_name.split('_')[1][1]) - 1\n",
    "        cam_list[cam_id].append(image_path)\n",
    "    return cam_list\n",
    "\n",
    "def cam_split_dataset(person_dict, save_dir):\n",
    "    save_dir = Path(save_dir)\n",
    "    for person, cams in person_dict.items():\n",
    "        person_dir = save_dir/person\n",
    "        person_dir.mkdir(parents=True, exist_ok=True)\n",
    "        for cam, image_paths in cams.items():\n",
    "            cam_dir = person_dir/str(cam)\n",
    "            cam_dir.mkdir(parents=True, exist_ok=True)\n",
    "            for image_path in image_paths:\n",
    "                img = Image.open(image_path)\n",
    "                # Resize the image to 256x128\n",
    "                img = img.resize((128, 256)) \n",
    "                image_path = cam_dir/image_path.name\n",
    "                img.save(image_path)\n",
    "\n",
    "def strip_name(filename):\n",
    "    # Use regex to remove the 'transfered[some_number]' part\n",
    "    stripped_filename = re.sub(r'transfered\\d+', '', filename)\n",
    "    return stripped_filename\n",
    "\n",
    "def transfered_split(dataset_path):\n",
    "    image_paths = sorted(list(dataset_path.glob('bounding_box_train/*.jpg')))\n",
    "    transfered_dict = {}\n",
    "    for image_path in image_paths:\n",
    "        image_name = strip_name(image_path.name)\n",
    "        if image_name in transfered_dict.keys():\n",
    "            transfered_dict[image_name].append(image_path)\n",
    "        else:\n",
    "            transfered_dict[image_name] = [image_path]\n",
    "    return transfered_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "market_all_dataset_path = Path('/home/jun/ReID_Dataset/Market-1501-v15.09.15-stargan-allcam')\n",
    "market_all_tranfered_split = transfered_split(market_all_dataset_path)\n",
    "duke_all_dataset_path = Path('/home/jun/ReID_Dataset/DukeMTMC-reID-stargan-allcam')\n",
    "duke_all_tranfered_split = transfered_split(duke_all_dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pick_and_display_images(image_lists, num_lists=6, save_dir='all_cam_visualize/sample.jpg'):\n",
    "    \n",
    "    # Pick 6 random lists\n",
    "    selected_lists = random.sample(image_lists, num_lists)\n",
    "    \n",
    "    # Open and resize images, store in a list of lists\n",
    "    resized_images = []\n",
    "    for img_list in selected_lists:\n",
    "        row_images = [Image.open(img_path).resize((128, 256)) for img_path in img_list]\n",
    "        resized_images.append(row_images)\n",
    "    \n",
    "    # Calculate the size of the final merged image\n",
    "    total_width = 128 * len(selected_lists[0])\n",
    "    total_height = 256 * num_lists\n",
    "    \n",
    "    # Create a new blank image with the calculated size\n",
    "    merged_image = Image.new('RGB', (total_width, total_height))\n",
    "    \n",
    "    # Paste the images into the merged image\n",
    "    for row_index, row_images in enumerate(resized_images):\n",
    "        for col_index, img in enumerate(row_images):\n",
    "            merged_image.paste(img, (col_index * 128, row_index * 256))\n",
    "    merged_image.save(save_dir) \n",
    "    # Display the merged image\n",
    "    #merged_image.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pick_and_display_images(list(market_all_tranfered_split.values()),3, 'all_cam_visualize/all_cam_market.jpg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pick_and_display_images(list(duke_all_tranfered_split.values()),3, 'all_cam_visualize/all_cam_duke.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "market_dataset_path = Path('/Volumes/NVMESSD1TB/PersonReID_Research/ReID_Dataset/Market-1501-v15.09.15')\n",
    "market_person_cam_split = person_cam_split(market_dataset_path, 6)\n",
    "market_full_cam = cam_filter(market_person_cam_split, 6)\n",
    "market_cam_list = cam_split(market_dataset_path, 6)\n",
    "cam_split_dataset(market_full_cam, './cam_split_market')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "duke_dataset_path = Path('/Volumes/NVMESSD1TB/PersonReID_Research/ReID_Dataset/DukeMTMC-reID')\n",
    "duke_person_cam_split = person_cam_split(duke_dataset_path, 8)\n",
    "duke_full_cam = cam_filter(duke_person_cam_split, 4)\n",
    "duke_cam_list = cam_split(duke_dataset_path, 8)\n",
    "cam_split_dataset(duke_full_cam, './cam_split_duke2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_random_images(image_lists):\n",
    "    # Create a figure to display multiple images\n",
    "    fig, axes = plt.subplots(1, len(image_lists), figsize=(15, 5))\n",
    "\n",
    "    for i, image_list in enumerate(image_lists):\n",
    "        # Pick a random image from the current sublist\n",
    "        random_image_path = random.choice(image_list)\n",
    "        \n",
    "        # Load and display the image\n",
    "        img = mpimg.imread(random_image_path)\n",
    "        axes[i].imshow(img)\n",
    "        axes[i].axis('off')  # Hide the axis\n",
    "\n",
    "    # Adjust layout and show the images\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_random_images_from_dict(person_dict, num_persons=6, num_lists=6):\n",
    "    # Randomly select num_persons keys (person_ids) from the dictionary\n",
    "    selected_persons = random.sample(list(person_dict.keys()), num_persons)\n",
    "    \n",
    "    for person_id in selected_persons:\n",
    "        image_lists = person_dict[person_id]\n",
    "        \n",
    "        # Ensure there are enough lists to sample\n",
    "        if len(image_lists) < num_lists:\n",
    "            print(f\"Not enough image lists for person {person_id}\")\n",
    "            continue\n",
    "        \n",
    "        # Randomly select num_lists sublists\n",
    "        selected_lists = random.sample(image_lists, num_lists)\n",
    "        \n",
    "        # Create a figure to display multiple images\n",
    "        fig, axes = plt.subplots(1, num_lists, figsize=(15, 5))\n",
    "        \n",
    "        for i, image_list in enumerate(selected_lists):\n",
    "            # Pick a random image from the current sublist\n",
    "            random_image_path = random.choice(image_list)\n",
    "            \n",
    "            # Load and display the image\n",
    "            img = mpimg.imread(random_image_path)\n",
    "            axes[i].imshow(img)\n",
    "            axes[i].axis('off')  # Hide the axis\n",
    "        \n",
    "        # Adjust layout and show the images\n",
    "        plt.tight_layout()\n",
    "        plt.suptitle(f'Person ID: {person_id}')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cam_visualize(cam_list, images_per_cam=6):\n",
    "    selected_images = []\n",
    "    \n",
    "    for camera_images in cam_list:\n",
    "        # Ensure there are enough images in each camera view\n",
    "        if len(camera_images) < images_per_cam:\n",
    "            print(f\"Not enough images in camera view: {camera_images}\")\n",
    "            continue\n",
    "        \n",
    "        # Randomly select num_images_per_camera images from each camera view\n",
    "        selected_images.append(random.sample(camera_images, images_per_cam))\n",
    "    \n",
    "    # Determine the dimensions for the big image\n",
    "    img_width, img_height = 128, 256\n",
    "    num_cameras = len(selected_images)\n",
    "    big_image_width = img_width * images_per_cam\n",
    "    big_image_height = img_height * num_cameras\n",
    "    \n",
    "    # Create a new big image\n",
    "    big_image = Image.new('RGB', (big_image_width, big_image_height))\n",
    "    \n",
    "    # Paste the selected images into the big image\n",
    "    for i, camera_images in enumerate(selected_images):\n",
    "        for j, image_path in enumerate(camera_images):\n",
    "            # Load and resize the image\n",
    "            img = Image.open(image_path)\n",
    "            img = img.resize((img_width, img_height))\n",
    "            \n",
    "            # Calculate the position to paste the image\n",
    "            x_offset = j * img_width\n",
    "            y_offset = i * img_height\n",
    "            \n",
    "            # Paste the image into the big image\n",
    "            big_image.paste(img, (x_offset, y_offset))\n",
    "    \n",
    "    # Display the big image\n",
    "    plt.figure(figsize=(20, 20))\n",
    "    plt.imshow(big_image)\n",
    "    plt.axis('off')  # Hide the axis\n",
    "    plt.show()\n",
    "\n",
    "def cam_visualize_vertically(image_lists, num_images_per_camera=6):\n",
    "    selected_images = []\n",
    "    \n",
    "    for camera_images in image_lists:\n",
    "        # Ensure there are enough images in each camera view\n",
    "        if len(camera_images) < num_images_per_camera:\n",
    "            print(f\"Not enough images in camera view: {camera_images}\")\n",
    "            continue\n",
    "        \n",
    "        # Randomly select num_images_per_camera images from each camera view\n",
    "        selected_images.append(random.sample(camera_images, num_images_per_camera))\n",
    "    \n",
    "    # Determine the dimensions for the big image\n",
    "    img_width, img_height = 128, 256\n",
    "    num_cameras = len(selected_images)\n",
    "    big_image_width = img_width * num_cameras\n",
    "    big_image_height = img_height * num_images_per_camera\n",
    "    \n",
    "    # Create a new big image\n",
    "    big_image = Image.new('RGB', (big_image_width, big_image_height))\n",
    "    \n",
    "    # Paste the selected images into the big image\n",
    "    for i, camera_images in enumerate(selected_images):\n",
    "        for j, image_path in enumerate(camera_images):\n",
    "            # Load and resize the image\n",
    "            img = Image.open(image_path)\n",
    "            img = img.resize((img_width, img_height))\n",
    "            \n",
    "            # Calculate the position to paste the image\n",
    "            x_offset = i * img_width\n",
    "            y_offset = j * img_height\n",
    "            \n",
    "            # Paste the image into the big image\n",
    "            big_image.paste(img, (x_offset, y_offset))\n",
    "    \n",
    "    # Display the big image\n",
    "    plt.figure(figsize=(20, 20))\n",
    "    plt.imshow(big_image)\n",
    "    plt.axis('off')  # Hide the axis\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def display_random_images_from_dict(person_dict, num_persons=6, num_lists=6):\n",
    "    # Randomly select num_persons keys (person_ids) from the dictionary\n",
    "    selected_persons = random.sample(list(person_dict.keys()), num_persons)\n",
    "    print(selected_persons)\n",
    "    images = []\n",
    "    \n",
    "    for person_id in selected_persons:\n",
    "        image_lists = list(person_dict[person_id].values())\n",
    "\n",
    "        # Ensure there are enough lists to sample\n",
    "        if len(image_lists) < num_lists:\n",
    "            print(f\"Not enough image lists for person {person_id}\")\n",
    "            continue\n",
    "        \n",
    "        # Randomly select num_lists sublists\n",
    "        selected_lists = random.sample(image_lists, num_lists)\n",
    "        \n",
    "        for image_list in selected_lists:\n",
    "            # Pick a random image from the current sublist\n",
    "            random_image_path = random.choice(image_list)\n",
    "            # Load the image\n",
    "            img = Image.open(random_image_path)\n",
    "            # Resize the image to 256x128\n",
    "            img = img.resize((128, 256))\n",
    "            # Append the image to the list\n",
    "            images.append(img)\n",
    "    \n",
    "    # Merge images into one big image\n",
    "    total_width = 128 * num_lists\n",
    "    total_height = 256 * num_persons\n",
    "    big_image = Image.new('RGB', (total_width, total_height))\n",
    "    \n",
    "    y_offset = 0\n",
    "    for i in range(num_persons):\n",
    "        x_offset = 0\n",
    "        for j in range(num_lists):\n",
    "            big_image.paste(images[i * num_lists + j], (x_offset, y_offset))\n",
    "            x_offset += 128\n",
    "        y_offset += 256\n",
    "    \n",
    "    # Display the big image\n",
    "    plt.figure(figsize=(15, 15))\n",
    "    plt.imshow(big_image)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
